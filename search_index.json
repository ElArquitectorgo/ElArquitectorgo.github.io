[["index.html", "Trabajo final de curso Chapter 1 Introducción", " Trabajo final de curso Víctor Guirado Osorio 2023-05-22 Chapter 1 Introducción En este trabajo vamos a estudiar a pacientes con insuficiencia cardíaca. Mediante el uso de estadística y machine learning vamos a diseñar modelos predictivos del evento Death. Por lo que sabemos con sólamente las variables serum creatinine y ejection fraction podemos predecir el evento DEATH de manera más precisa que si usásemos todas las variables de estudio (Davide Chicco 2020). Finalmente compararemos los resultados de nuestro análisis con los citados. Referencias "],["methods.html", "Chapter 2 Metodología", " Chapter 2 Metodología Contamos con un dataset de 299 muestras que analizaremos en detalle mediante análisis descriptivo e inferencia estadística con el fin de preparar los datos de cara a usarlos para entrenar correctamente a los modelos de machine learning. Para encontrar el mejor modelo predictivo vamos a comparar los resultados de distintos algoritmos como son las redes neuronales, máquinas de soporte vectorial y árboles de decisión, basándonos principalmente en el área bajo la curva ROC, así como en el f1-score. Usaremos librerías de R para realizar selección de variables, filtrado o wrapper. Para poder obtener y comparar los resultados vamos a implementar un método de validación cruzada para hacer una estimación honesta de la capacidad predictiva de cada modelo. En el capítulo 5 se explicará en detalle cómo. Iremos realizando pruebas con múltiples parámetros en cada algoritmo y evaluando los resultados de cada prueba para ir acotando los parámetros óptimos. Esta evaluación estará basada en el número de veces que aparece ese parámetro en las k iteraciones, el AUC medio asociado a ese parámetro y en caso de dudas, atendiendo al criterio personal. "],["dataset.html", "Chapter 3 Dataset", " Chapter 3 Dataset Primero de todo vamos a ver qué forma tienen nuestros datos. datos &lt;- read.table(file=&quot;D:/IngSalud/3º/Minería/Insuficiencia_cardíaca/datos.csv&quot;, sep=&quot;,&quot;, dec=&quot;.&quot;, header=T, stringsAsFactors = T) str(datos) ## &#39;data.frame&#39;: 299 obs. of 13 variables: ## $ age : num 75 55 65 50 65 90 75 60 65 80 ... ## $ anaemia : int 0 0 0 1 1 1 1 1 0 1 ... ## $ creatinine_phosphokinase: int 582 7861 146 111 160 47 246 315 157 123 ... ## $ diabetes : int 0 0 0 0 1 0 0 1 0 0 ... ## $ ejection_fraction : int 20 38 20 20 20 40 15 60 65 35 ... ## $ high_blood_pressure : int 1 0 0 0 0 1 0 0 0 1 ... ## $ platelets : num 265000 263358 162000 210000 327000 ... ## $ serum_creatinine : num 1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ... ## $ serum_sodium : int 130 136 129 137 116 132 137 131 138 133 ... ## $ sex : int 1 1 1 1 0 1 1 1 0 1 ... ## $ smoking : int 0 0 1 0 0 1 0 1 0 1 ... ## $ time : int 4 6 7 7 8 8 10 10 10 10 ... ## $ DEATH_EVENT : int 1 1 1 1 1 1 1 1 1 1 ... Para categorizar las variables binarias usaremos la función as.factor de R. datos$anaemia &lt;- as.factor(datos$anaemia) datos$diabetes &lt;- as.factor(datos$diabetes) datos$high_blood_pressure &lt;- as.factor(datos$high_blood_pressure) datos$platelets &lt;- datos$platelets/1000 datos$sex &lt;- as.factor(datos$sex) datos$smoking &lt;- as.factor(datos$smoking) datos$DEATH_EVENT &lt;- as.factor(datos$DEATH_EVENT) datos$time &lt;- NULL # La eliminamos acorde al enunciado del trabajo str(datos) ## &#39;data.frame&#39;: 299 obs. of 12 variables: ## $ age : num 75 55 65 50 65 90 75 60 65 80 ... ## $ anaemia : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 2 2 2 2 2 1 2 ... ## $ creatinine_phosphokinase: int 582 7861 146 111 160 47 246 315 157 123 ... ## $ diabetes : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 2 1 1 2 1 1 ... ## $ ejection_fraction : int 20 38 20 20 20 40 15 60 65 35 ... ## $ high_blood_pressure : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 1 1 1 1 2 1 1 1 2 ... ## $ platelets : num 265 263 162 210 327 ... ## $ serum_creatinine : num 1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ... ## $ serum_sodium : int 130 136 129 137 116 132 137 131 138 133 ... ## $ sex : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 1 2 2 2 1 2 ... ## $ smoking : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 2 1 1 2 1 2 1 2 ... ## $ DEATH_EVENT : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... Como podemos observar contamos con 6 variables binarias y 6 numéricas. Más adelante veremos si categorizamos alguna más. Al tener nuestro dataset tantas columnas hemos tenido que dividir en dos la tabla (ver tablas 3.1 y 3.2). Table 3.1: Columnas 1-6 age anaemia cpk diabetes ejection_fraction high_blood_pressure 75 0 582 0 20 1 55 0 7861 0 38 0 65 0 146 0 20 0 50 1 111 0 20 0 65 1 160 1 20 0 Table 3.2: Columnas 7-12 platelets serum_creatinine serum_sodium sex smoking DEATH 265.000 1.9 130 1 0 1 263.358 1.1 136 1 0 1 162.000 1.3 129 1 1 1 210.000 1.9 137 1 0 1 327.000 2.7 116 0 0 1 Ya salta a la vista que las variables vamos a tener que normalizarlas. La diferencia de magnitud entre los datos va a hacer que para los algoritmos unas variables eclipsen completamente a otras, por ejemplo la variable platelets con respecto a serum_creatinine es 100 veces mayor en magnitud. También hay desbalanceo dentro de las propias variables, esto habrá que tratarlo más adelante. "],["ana.html", "Chapter 4 Estadísitca descriptiva e inferencia estadística 4.1 Análisis univariante 4.2 Análisis bivariante 4.3 Análisis multivariante", " Chapter 4 Estadísitca descriptiva e inferencia estadística Vamos a realizar ahora un análisis más en profundidad de nuestro dataset, empezando por un análisis univariante, seguido del análisis multivariante. Con el análisis univariante pretendemos estudiar las variables de forma individual para ver si tenemos que modificarlas de alguna manera de cara a facilitar la construcción de los futuros modelos. Luego en el análisis bivariante vamos a estudiar la relación de cada variable con la variable de estudio. Finalmente en el análisis multivariante vamos a utilizar la función StepAIC para encontrar aquellas combinaciones que a priori funcionan mejor para explicar la variable de estudio. 4.1 Análisis univariante Hemos representado en la tabla 4.1 las variables numéricas, donde se muestra el mínimo, la mediana, la media y el máximo de cada variable, y en otra tabla 4.2 las variables categóricas, para ir entendiendo un poco más la distribución de los datos. Table 4.1: Resumen de las variables numéricas Min. Median Mean Max. age 40.0 60.0 60.83389 95.0 creatinine_phosphokinase 23.0 250.0 581.83946 7861.0 ejection_fraction 14.0 38.0 38.08361 80.0 platelets 25.1 262.0 263.35803 850.0 serum_creatinine 0.5 1.1 1.39388 9.4 serum_sodium 113.0 137.0 136.62542 148.0 Table 4.2: Resumen de las variables categóricas 0 1 anaemia 170 129 high_blood_pressure 194 105 diabetes 174 125 sex 105 194 smoking 203 96 DEATH_EVENT 203 96 Las variables binarias están balanceadas y no van a suponer ningún problema a la hora de dividir el dataset en datos de entrenamiento, validación y test. No podemos decir lo mismo de las variables numéricas, concretamente CPK y platelets, las cuales vamos a representar en un gráfico para ver si podemos agruparlas. Efectivamente parece una buena idea categorizar ambas variables, ya que presentan una distribución muy dispersa. datos$creatinine_phosphokinase &lt;- cut(datos$creatinine_phosphokinase, breaks=c(0,1000,2000, max(datos$creatinine_phosphokinase))) summary(datos$creatinine_phosphokinase) ## (0,1e+03] (1e+03,2e+03] (2e+03,7.86e+03] ## 263 18 18 datos$platelets &lt;- cut(datos$platelets, breaks=c(0,200,400, max(datos$platelets))) summary(datos$platelets) ## (0,200] (200,400] (400,850] ## 63 216 20 Así hemos conseguido agrupar en tres grupos este par de variables evitando normalizar los datos; habiendo tan pocas muestras y teniendo en cuenta la gran dispersión de los datos es una alternativa que nos va a ayudar con los clasificadores. Ahora vamos a estudiar la distribución de las variables numéricas. shapiro.test(datos$age) ## ## Shapiro-Wilk normality test ## ## data: datos$age ## W = 0.97547, p-value = 5.35e-05 shapiro.test(datos$serum_creatinine) ## ## Shapiro-Wilk normality test ## ## data: datos$serum_creatinine ## W = 0.55147, p-value &lt; 2.2e-16 shapiro.test(datos$serum_sodium) ## ## Shapiro-Wilk normality test ## ## data: datos$serum_sodium ## W = 0.93903, p-value = 9.215e-10 shapiro.test(datos$ejection_fraction) ## ## Shapiro-Wilk normality test ## ## data: datos$ejection_fraction ## W = 0.94732, p-value = 7.216e-09 El p-valor nos sale 0 en todas y por tanto no hay distribución normal de los datos, usaremos pues el test de Wilcoxon para compararlas con la variable de estudio. 4.2 Análisis bivariante Ahora analizaremos cada variable con la variable de estudio. Empezamos con las numéricas. A priori parece haber relación entre las variables numéricas y la variable de estudio. wilcox.test(datos$age ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$age by datos$DEATH_EVENT ## W = 7121, p-value = 0.0001668 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(datos$serum_creatinine ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$serum_creatinine by datos$DEATH_EVENT ## W = 5298, p-value = 1.581e-10 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(datos$serum_sodium ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$serum_sodium by datos$DEATH_EVENT ## W = 12262, p-value = 0.0002928 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(datos$ejection_fraction ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$ejection_fraction by datos$DEATH_EVENT ## W = 13176, p-value = 7.368e-07 ## alternative hypothesis: true location shift is not equal to 0 Confirmamos que las variables están relacionadas con el evento DEATH ya que el p-valor nos ha salido 0. Ahora veamos las variables categóricas. A simple vista parece que no hay relación alguna entre las variables categóricas y la variable de estudio, sin embargo vamos a comprobarlo haciendo el test chisq.test. chisq.test(xtabs(~ datos$anaemia + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$anaemia + datos$DEATH_EVENT) ## X-squared = 1.0422, df = 1, p-value = 0.3073 chisq.test(xtabs(~ datos$high_blood_pressure + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$high_blood_pressure + datos$DEATH_EVENT) ## X-squared = 1.5435, df = 1, p-value = 0.2141 chisq.test(xtabs(~ datos$creatinine_phosphokinase + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test ## ## data: xtabs(~datos$creatinine_phosphokinase + datos$DEATH_EVENT) ## X-squared = 2.3908, df = 2, p-value = 0.3026 chisq.test(xtabs(~ datos$platelets + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test ## ## data: xtabs(~datos$platelets + datos$DEATH_EVENT) ## X-squared = 3.0754, df = 2, p-value = 0.2149 chisq.test(xtabs(~ datos$diabetes + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$diabetes + datos$DEATH_EVENT) ## X-squared = 2.1617e-30, df = 1, p-value = 1 chisq.test(xtabs(~ datos$sex + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$sex + datos$DEATH_EVENT) ## X-squared = 0, df = 1, p-value = 1 chisq.test(xtabs(~ datos$smoking + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$smoking + datos$DEATH_EVENT) ## X-squared = 0.0073315, df = 1, p-value = 0.9318 Y como sospechábamos para todos el p-valor es mayor de 0.05 y por tanto las variables no están relacionadas. 4.3 Análisis multivariante Más adelante realizaremos la selección de variables de forma más adecuada pero mientras tanto mostramos el resultado del StepAIC utilizando todos los datos. # Modelo de regresión logística lr &lt;- stepAIC(glm(DEATH_EVENT~., data = datos, family = binomial(&quot;logit&quot;)), direction = &quot;both&quot;, trace = 0) summary(lr) ## ## Call: ## glm(formula = DEATH_EVENT ~ age + ejection_fraction + high_blood_pressure + ## serum_creatinine + serum_sodium, family = binomial(&quot;logit&quot;), ## data = datos) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.3376 -0.7712 -0.4978 0.8484 2.4941 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 3.95483 4.43338 0.892 0.372 ## age 0.05105 0.01249 4.086 4.38e-05 *** ## ejection_fraction -0.06705 0.01440 -4.657 3.21e-06 *** ## high_blood_pressure1 0.44276 0.29566 1.498 0.134 ## serum_creatinine 0.65503 0.16421 3.989 6.64e-05 *** ## serum_sodium -0.04774 0.03226 -1.480 0.139 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 375.35 on 298 degrees of freedom ## Residual deviance: 300.85 on 293 degrees of freedom ## AIC: 312.85 ## ## Number of Fisher Scoring iterations: 5 "],["kfold.html", "Chapter 5 Validación y evaluación 5.1 K-fold cross validation 5.2 Métricas", " Chapter 5 Validación y evaluación 5.1 K-fold cross validation Para la validación interna de los modelos vamos a implementar el procedimiento k-fold cross validation. A continuación mostraremos los pasos de nuestra implementación, donde se ha optado por no hacer un 5x2 sino un \\(k\\cdot (k-1)\\). Dividimos el dataset en k cajas. Asignamos 1 caja a test y k - 1 cajas a entrenamiento. Realizamos selección de variables con los datos de entrenamiento. Dividimos los datos de entrenamiento en 1 caja para validación y k - 2 para entrenamiento. Calculamos el AUC del primer conjunto de parámetros con los datos nuevos de entrenamiento y validación. Repetimos k - 2 veces más el último punto, moviendo las cajas hasta que cada caja del subconjunto se haya usado como validación. Se calcula la media del AUC y se realiza el mismo proceso con el siguiente conjunto de parámetros. Una vez probado todos los conjuntos de parámetros escogemos aquel con mayor AUC medio. Se calcula el AUC del modelo escogido usando ahora todos los datos de entrenamiento originales y los de test. Se repite todo lo anterior k - 1 veces más moviendo las cajas de entrenamiento original y la de test hasta que cada caja se haya usado como test. Al algoritmo se le pasarán como parámetros el dataset, el número de veces que queremos dividir el dataset, el algoritmo de aprendizaje, el método de selección de variables y los parámetros del algoritmo de aprendizaje. A continuación mostramos las funciones que implementan el algoritmo. Para este problema sería más adecuado el uso de un lenguaje orientado a objetos. get.variables &lt;- function(method, datos) { if (method == &quot;filtrado&quot;) { subset &lt;- chi.squared(DEATH_EVENT~., datos) subset &lt;- cutoff.k(subset, 5) return (as.simple.formula(subset, &quot;DEATH_EVENT&quot;)) } else if (method == &quot;wrapper&quot;) { lr &lt;- stepAIC(glm(DEATH_EVENT~., data = datos, family = binomial(&quot;logit&quot;)), direction = &quot;both&quot;, trace = 0) return (lr$formula) } } get.predictions &lt;- function(model, variables, parameters, training, test) { if (model == &quot;nn&quot;) { nn.fit &lt;- nnet(variables, data=training, size=parameters[[1]], maxit=1000, decay=parameters[[2]], trace=FALSE) return (predict(nn.fit, test, type=&quot;raw&quot;)) } else if (model == &quot;svm&quot;) { svm.fit &lt;- svm(variables, data=training, cost = parameters[[1]], gamma = parameters[[2]], probability=TRUE) pred &lt;- predict(svm.fit, test,probability=TRUE) return (attr(pred, which=&quot;probabilities&quot;)[,2]) } else if (model == &quot;tree&quot;) { dt.fit &lt;- rpart(variables, data=training, control = rpart.control(cp=parameters[[1]])) return(predict(dt.fit, test, type=&quot;vector&quot;)) } } k.fold.cross.validation &lt;- function(datos, k, model, method, parameters) { results &lt;- unname(data.frame()) parameters &lt;- expand.grid(pmt1 = parameters[[1]], pmt2 = parameters[[2]]) first.folded.data &lt;- createFolds(datos$DEATH_EVENT, k) for (i in 1:k) { best.inner.auc = 0 best.inner.model = parameters[1,] training.set &lt;- data.frame(datos[-unlist(first.folded.data[][i]),]) test.set &lt;- data.frame(datos[unlist(first.folded.data[][i]),]) second.folded.data &lt;- createFolds(training.set$DEATH_EVENT, k-1) variables &lt;- get.variables(method, datos) for (m in 1:nrow(parameters)) { # Calculamos la media de aucs de un mismo conjunto de parámetros model.auc &lt;- c() for (j in 1:(k-1)) { sub.training.set &lt;- data.frame(datos[-unlist(second.folded.data[][j]),]) validation.set &lt;- data.frame(datos[unlist(second.folded.data[][j]),]) pred &lt;- get.predictions(model, variables, parameters[m,], sub.training.set, validation.set) model.auc &lt;- c(model.auc, pROC::auc(validation.set$DEATH_EVENT, as.vector(pred), levels=c(0, 1))) } if (mean(model.auc) &gt; best.inner.auc) { best.inner.auc = mean(model.auc) best.inner.model = parameters[m,] } } pred &lt;- get.predictions(model, variables, best.inner.model, training.set, test.set) model.métricas = get.métricas(test.set$DEATH_EVENT, as.vector(pred), 0.5) results = rbind(results, unname(c(toString(variables), best.inner.model, model.métricas[1], model.métricas[4], model.métricas[5]))) } if (model == &quot;nn&quot;) names(results) &lt;- c(&quot;Variables&quot;, &quot;Size&quot;, &quot;Decay&quot;, &quot;ACC&quot;, &quot;F1-score&quot;, &quot;AUC&quot;) else if (model == &quot;svm&quot;) names(results) &lt;- c(&quot;Variables&quot;, &quot;Cost&quot;, &quot;Gamma&quot;, &quot;ACC&quot;, &quot;F1-score&quot;, &quot;AUC&quot;) else if (model == &quot;tree&quot;) { results &lt;- results[, -3] names(results) &lt;- c(&quot;Variables&quot;, &quot;Cp&quot;, &quot;ACC&quot;, &quot;F1-score&quot;, &quot;AUC&quot;) } return (results) } 5.2 Métricas Para la evaluación de los modelos nos guíamos por el AUC, ya que las métricas de precisión, especificidad y sensibilidad están determinadas por el valor que fijemos como umbral. Sin embargo aquí mostramos el método que cálcula todos esos valores. get.métricas &lt;- function(real, pred, umbral, print_matrix = FALSE) { TP = length(which(pred &gt;= umbral &amp; real == 1)) TN = length(which(pred &lt;= umbral &amp; real == 0)) acc = (TP + TN) / length(pred) FP = length(which(pred &gt;= umbral &amp; real == 0)) FN = length(which(pred &lt;= umbral &amp; real == 1)) especificidad = TN / (TN + FP) sensibilidad = TP / (TP + FN) f1score = 2 * acc * sensibilidad / (acc + sensibilidad) auc = pROC::auc(real, pred, levels=c(0, 1)) v = cbind(c(TN, FN),c(FP, TP)) colnames(v) &lt;- c(&quot;F&quot;,&quot;T&quot;) rownames(v) &lt;- c(&quot;F&quot;,&quot;T&quot;) if (print_matrix) print(v) return(c(acc, especificidad, sensibilidad, f1score, auc)) } "],["resultados.html", "Chapter 6 Resultados 6.1 Redes Neuronales 6.2 Máquinas de soporte vectorial 6.3 Árboles de decisión", " Chapter 6 Resultados A continuación vamos a mostrar los resultados de los mejores modelos obtenidos de redes neuronales, máquinas de soporte vectorial y árboles de decisión. Para cada uno se ha empleado el método de filtrado chi.squared y el método wrapper stepAIC. Se muestran los valores de precisión, f1-score, y auc. Es importante destacar que las dos primeras medidas están completamente condicionadas por el umbral escogido para determinar qué probabilidades consideremos como 0 o 1. Aquí se ha escogido manualmente 0.5 ya que no hemos podido obtenerlo de forma automática, pero el código para hacerlo sería el siguiente: # Calcular el punto de corte óptimo para las métricas de ACC y F1-score. cost.perf = performance(pred, &quot;cost&quot;) pred@cutoffs[[1]][which.min(cost.perf@y.values[[1]])] Lo dejamos así por si en un futuro conseguimos arreglar el problema no tener que modificar las tablas. Table 6.1: Métricas de los algoritmos para k=10 ACC F1score Min. AUC Mean AUC Max. AUC NN wrapper 0.7600371 0.6288799 0.6666667 0.7873333 0.9222222 NN filtrado 0.7392918 0.6011562 0.6166667 0.7604894 0.8888889 SVM wrapper 0.2575454 0.3449116 0.6100000 0.7970265 0.9450000 SVM filtrado 0.2605933 0.3476380 0.6571429 0.8022989 0.8950000 DT wrapper 0.3209121 0.4858151 0.4861111 0.6900794 0.9261905 DT filtrado 0.3209529 0.4858201 0.6722222 0.7273810 0.7750000 Podemos observar que el mayor AUC medio se ha obtenido con SVM usando un método de filtrado para la selección de variables. Todos los modelos han obtenido resultados muy similares, y atendiendo al AUC máximo, se consiguen valores muy buenos. El conjunto de variables correspondiente para ese modelo es el siguiente: serum_creatinine, ejection_fraction, age, serum_sodium y platelets. Corresponde a lo visto en el análisis bivariante, donde nuestras cuatro variables numéricas estaban relacionadas con el evento Death. Vimos que platelets no estaba relacionada pero para el conjunto de datos parece que incluirla junto al resto de variables ayuda con la predicción. Para más detalles de los resultados obtenidos en cada algoritmo ver las siguientes subsecciones. Ahora vamos a comprobar si obtenemos mejores resultados usando sólo las variables serum_creatinine y ejection_fraction como mencionamos al principio del trabajo, cuyos resultados podemos ver en la tabla 6.2. También vamos a ver los resultados utilizando únicamente las variables relacionadas obtenidas en el capítulo 4 (ver tabla 6.3). Table 6.2: Métricas de los algoritmos (dos variables) para k=10 Min. AUC Mean AUC Max. AUC NN wrapper 0.6350000 0.7763810 0.9083333 NN filtrado 0.4250000 0.7291905 0.8475000 SVM wrapper 0.6350000 0.7664815 0.9050000 SVM filtrado 0.6650000 0.7630053 0.9050000 DT wrapper 0.6250000 0.6994444 0.7301587 DT filtrado 0.5111111 0.6847222 0.8250000 Table 6.3: Métricas de los algoritmos (cuatro variables) para k=10 Min. AUC Mean AUC Max. AUC NN wrapper 0.6333333 0.7854735 0.9500000 NN filtrado 0.6166667 0.7681508 0.9050000 SVM wrapper 0.6714286 0.7895476 0.9444444 SVM filtrado 0.6611111 0.7848254 0.9000000 DT wrapper 0.6333333 0.7114286 0.8285714 DT filtrado 0.5158730 0.6974603 0.9523810 Podemos juntar todos los datos obtenidos en las tres pruebas, calculando la media de cada columna, y obtenemos la siguiente tabla: Table 6.4: Métricas de los algoritmos para k=10 Min. AUC Mean AUC Max. AUC serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6181349 0.7607681 0.8920503 serum_creatinine + ejection_fraction + age + serum_sodium 0.6219577 0.7561477 0.9133995 serum_creatinine + ejection_fraction 0.5826852 0.7365375 0.8534987 Sorprendentemente los mejores resultados no se han obtenido usando sólo dos variables. Vemos que no hay mucha diferencia entre usar un conjunto de variables u otro, y preferiblemente vamos a tender siempre a simplificar el modelo. 6.1 Redes Neuronales Table 6.5: Resultados NN usando wrapper Variables ACC F1-score AUC ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7931 0.7854 0.8556 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7586 0.6414 0.7778 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7667 0.6053 0.8600 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7419 0.4272 0.7952 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7097 0.6502 0.6667 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8333 0.8163 0.7500 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6667 0.4138 0.6800 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7097 0.4217 0.7381 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7586 0.7097 0.8278 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8621 0.8178 0.9222 Table 6.5: Resultados NN usando filtrado Variables ACC F1-score AUC ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7586 0.6414 0.8889 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8667 0.7091 0.8850 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7097 0.4217 0.8095 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7000 0.5091 0.6900 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6000 0.5455 0.6400 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8000 0.8421 0.8148 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6897 0.4494 0.6167 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7097 0.6502 0.7667 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8000 0.5333 0.8100 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7586 0.7097 0.6833 summary(nn.wrapper.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6667 0.7411 0.7865 0.7873 0.8486 0.9222 summary(nn.filtrado.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6167 0.6850 0.7881 0.7605 0.8136 0.8889 6.2 Máquinas de soporte vectorial Table 6.6: Resultados SVM usando wrapper Variables ACC F1-score AUC ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.2000 0.2400 0.8750 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.2333 0.3500 0.9450 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.3103 0.3655 0.7278 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.1333 0.1846 0.9150 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.2000 0.2667 0.8250 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4000 0.5333 0.6100 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.3226 0.4598 0.7190 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.2667 0.2963 0.7566 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.2333 0.3457 0.8413 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.2759 0.4073 0.7556 Table 6.6: Resultados SVM usando filtrado Variables ACC F1-score AUC ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2903 0.3673 0.6571 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2069 0.2824 0.8444 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2759 0.3687 0.7444 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2903 0.3673 0.8143 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2000 0.2857 0.8350 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2333 0.2947 0.8450 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.3000 0.4200 0.8300 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2333 0.3360 0.8950 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.2759 0.3404 0.7111 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.3000 0.4138 0.8466 summary(svm.wrapper.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6100 0.7347 0.7908 0.7970 0.8666 0.9450 summary(svm.filtrado.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6571 0.7619 0.8325 0.8023 0.8449 0.8950 6.3 Árboles de decisión Table 6.7: Resultados DT usando wrapper Variables F1-score AUC ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.5000 0.8000 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4878 0.7286 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4737 0.7583 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4737 0.4861 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4878 0.9262 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4737 0.5417 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.5000 0.6250 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.5000 0.6000 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4737 0.7778 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.4878 0.6571 Table 6.7: Resultados DT usando filtrado Variables F1-score AUC ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.4737 0.7389 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.4737 0.6722 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.5000 0.7250 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.5000 0.7750 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.5000 0.7500 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.5000 0.7500 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.4878 0.7024 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.4737 0.7333 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.4615 0.7222 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.4878 0.7048 summary(dt.wrapper.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.4861 0.6062 0.6929 0.6901 0.7729 0.9262 summary(dt.filtrado.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6722 0.7091 0.7292 0.7274 0.7472 0.7750 "],["conclusiones.html", "Chapter 7 Conclusiones", " Chapter 7 Conclusiones Hemos podido obtener modelos con un AUC mayor de 0.9 lo cual consideramos un éxito de cara a desplegar un futuro predictor. Sería conveniente contar con más datos ya que la muestra es relativamente pequeña. También hemos visto que en nuestro caso, con la configuración de nuestros algoritmos no hemos obtenido mejores resultados por simplificar el conjunto de variables a sólo dos. Por lo general, a lo largo de todas las pruebas, las máquinas de soporte vectorial son las que mejor han funcionado, y aunque la diferencia pueda no ser muy grande con respecto al resto de modelos, compensa por la rapidez de su entrenamiento. "],["referencias.html", "Referencias", " Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
