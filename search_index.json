[["index.html", "Trabajo final de curso Capítulo 1 Introducción", " Trabajo final de curso Víctor Guirado Osorio 2023-05-22 Capítulo 1 Introducción En este trabajo vamos a estudiar a pacientes con insuficiencia cardíaca. Mediante el uso de estadística y machine learning vamos a diseñar modelos predictivos del evento Death. Por lo que sabemos con sólamente las variables serum creatinine y ejection fraction podemos predecir el evento DEATH de manera más precisa que si usásemos todas las variables de estudio (Davide Chicco 2020). Finalmente compararemos los resultados de nuestro análisis con los citados. Referencias "],["methods.html", "Capítulo 2 Metodología", " Capítulo 2 Metodología Contamos con un dataset de 299 muestras que analizaremos en detalle mediante análisis descriptivo e inferencia estadística con el fin de preparar los datos de cara a usarlos para entrenar correctamente a los modelos de machine learning. Para encontrar el mejor modelo predictivo vamos a comparar los resultados de distintos algoritmos como son las redes neuronales, máquinas de soporte vectorial y árboles de decisión, basándonos principalmente en el área bajo la curva ROC. Usaremos librerías de R para realizar selección de variables, filtrado o wrapper. Para poder obtener y comparar los resultados vamos a implementar un método de validación cruzada para hacer una estimación honesta de la capacidad predictiva de cada modelo. En el capítulo 5 se explicará en detalle cómo. Iremos realizando pruebas con múltiples parámetros en cada algoritmo y evaluando los resultados de cada prueba para ir acotando los parámetros óptimos. Esta evaluación estará basada en el número de veces que aparece ese parámetro en las k iteraciones, el AUC medio asociado a ese parámetro y en caso de dudas, atendiendo al criterio personal. "],["dataset.html", "Capítulo 3 Dataset", " Capítulo 3 Dataset Primero de todo vamos a ver qué forma tienen nuestros datos. datos &lt;- read.table(file=&quot;D:/IngSalud/3º/Minería/Insuficiencia_cardíaca/datos.csv&quot;, sep=&quot;,&quot;, dec=&quot;.&quot;, header=T, stringsAsFactors = T) str(datos) ## &#39;data.frame&#39;: 299 obs. of 13 variables: ## $ age : num 75 55 65 50 65 90 75 60 65 80 ... ## $ anaemia : int 0 0 0 1 1 1 1 1 0 1 ... ## $ creatinine_phosphokinase: int 582 7861 146 111 160 47 246 315 157 123 ... ## $ diabetes : int 0 0 0 0 1 0 0 1 0 0 ... ## $ ejection_fraction : int 20 38 20 20 20 40 15 60 65 35 ... ## $ high_blood_pressure : int 1 0 0 0 0 1 0 0 0 1 ... ## $ platelets : num 265000 263358 162000 210000 327000 ... ## $ serum_creatinine : num 1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ... ## $ serum_sodium : int 130 136 129 137 116 132 137 131 138 133 ... ## $ sex : int 1 1 1 1 0 1 1 1 0 1 ... ## $ smoking : int 0 0 1 0 0 1 0 1 0 1 ... ## $ time : int 4 6 7 7 8 8 10 10 10 10 ... ## $ DEATH_EVENT : int 1 1 1 1 1 1 1 1 1 1 ... Para categorizar las variables binarias usaremos la función as.factor de R. datos$anaemia &lt;- as.factor(datos$anaemia) datos$diabetes &lt;- as.factor(datos$diabetes) datos$high_blood_pressure &lt;- as.factor(datos$high_blood_pressure) datos$platelets &lt;- datos$platelets/1000 datos$sex &lt;- as.factor(datos$sex) datos$smoking &lt;- as.factor(datos$smoking) datos$DEATH_EVENT &lt;- as.factor(datos$DEATH_EVENT) datos$time &lt;- NULL # La eliminamos acorde al enunciado del trabajo str(datos) ## &#39;data.frame&#39;: 299 obs. of 12 variables: ## $ age : num 75 55 65 50 65 90 75 60 65 80 ... ## $ anaemia : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 2 2 2 2 2 1 2 ... ## $ creatinine_phosphokinase: int 582 7861 146 111 160 47 246 315 157 123 ... ## $ diabetes : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 2 1 1 2 1 1 ... ## $ ejection_fraction : int 20 38 20 20 20 40 15 60 65 35 ... ## $ high_blood_pressure : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 1 1 1 1 2 1 1 1 2 ... ## $ platelets : num 265 263 162 210 327 ... ## $ serum_creatinine : num 1.9 1.1 1.3 1.9 2.7 2.1 1.2 1.1 1.5 9.4 ... ## $ serum_sodium : int 130 136 129 137 116 132 137 131 138 133 ... ## $ sex : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 1 2 2 2 1 2 ... ## $ smoking : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 2 1 1 2 1 2 1 2 ... ## $ DEATH_EVENT : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... Como podemos observar contamos con 6 variables binarias y 6 numéricas. Más adelante veremos si categorizamos alguna más. Al tener nuestro dataset tantas columnas hemos tenido que dividir en dos la tabla (ver tablas 3.1 y 3.2). Table 3.1: Columnas 1-6 age anaemia cpk diabetes ejection_fraction high_blood_pressure 75 0 582 0 20 1 55 0 7861 0 38 0 65 0 146 0 20 0 50 1 111 0 20 0 65 1 160 1 20 0 Table 3.2: Columnas 7-12 platelets serum_creatinine serum_sodium sex smoking DEATH 265.000 1.9 130 1 0 1 263.358 1.1 136 1 0 1 162.000 1.3 129 1 1 1 210.000 1.9 137 1 0 1 327.000 2.7 116 0 0 1 Ya salta a la vista que las variables vamos a tener que normalizarlas. La diferencia de magnitud entre los datos va a hacer que para los algoritmos unas variables eclipsen completamente a otras, por ejemplo la variable platelets con respecto a serum_creatinine es 100 veces mayor en magnitud. También hay desbalanceo dentro de las propias variables, esto habrá que tratarlo más adelante. "],["ana.html", "Capítulo 4 Estadísitca descriptiva e inferencia estadística 4.1 Análisis univariante 4.2 Análisis bivariante 4.3 Análisis multivariante", " Capítulo 4 Estadísitca descriptiva e inferencia estadística Vamos a realizar ahora un análisis más en profundidad de nuestro dataset, empezando por un análisis univariante, seguido del análisis multivariante. Con el análisis univariante pretendemos estudiar las variables de forma individual para ver si tenemos que modificarlas de alguna manera de cara a facilitar la construcción de los futuros modelos. Luego en el análisis bivariante vamos a estudiar la relación de cada variable con la variable de estudio. Finalmente en el análisis multivariante vamos a utilizar la función StepAIC para encontrar aquellas combinaciones que a priori funcionan mejor para explicar la variable de estudio. 4.1 Análisis univariante Hemos representado en la tabla 4.1 las variables numéricas, donde se muestra el mínimo, la mediana, la media y el máximo de cada variable, y en otra tabla 4.2 las variables categóricas, para ir entendiendo un poco más la distribución de los datos. Table 4.1: Resumen de las variables numéricas Min. Median Mean Max. age 40.0 60.0 60.83389 95.0 creatinine_phosphokinase 23.0 250.0 581.83946 7861.0 ejection_fraction 14.0 38.0 38.08361 80.0 platelets 25.1 262.0 263.35803 850.0 serum_creatinine 0.5 1.1 1.39388 9.4 serum_sodium 113.0 137.0 136.62542 148.0 Table 4.2: Resumen de las variables categóricas 0 1 anaemia 170 129 high_blood_pressure 194 105 diabetes 174 125 sex 105 194 smoking 203 96 DEATH_EVENT 203 96 Las variables binarias están balanceadas y no van a suponer ningún problema a la hora de dividir el dataset en datos de entrenamiento, validación y test. No podemos decir lo mismo de las variables numéricas, concretamente CPK y platelets, las cuales vamos a representar en un gráfico para ver si podemos agruparlas. Efectivamente parece una buena idea categorizar ambas variables, ya que presentan una distribución muy dispersa. datos$creatinine_phosphokinase &lt;- cut(datos$creatinine_phosphokinase, breaks=c(0,1000,2000, max(datos$creatinine_phosphokinase))) summary(datos$creatinine_phosphokinase) ## (0,1e+03] (1e+03,2e+03] (2e+03,7.86e+03] ## 263 18 18 datos$platelets &lt;- cut(datos$platelets, breaks=c(0,200,400, max(datos$platelets))) summary(datos$platelets) ## (0,200] (200,400] (400,850] ## 63 216 20 Así hemos conseguido agrupar en tres grupos este par de variables evitando normalizar los datos; habiendo tan pocas muestras y teniendo en cuenta la gran dispersión de los datos es una alternativa que nos va a ayudar con los clasificadores. Ahora vamos a estudiar la distribución de las variables numéricas. shapiro.test(datos$age) ## ## Shapiro-Wilk normality test ## ## data: datos$age ## W = 0.97547, p-value = 5.35e-05 shapiro.test(datos$serum_creatinine) ## ## Shapiro-Wilk normality test ## ## data: datos$serum_creatinine ## W = 0.55147, p-value &lt; 2.2e-16 shapiro.test(datos$serum_sodium) ## ## Shapiro-Wilk normality test ## ## data: datos$serum_sodium ## W = 0.93903, p-value = 9.215e-10 shapiro.test(datos$ejection_fraction) ## ## Shapiro-Wilk normality test ## ## data: datos$ejection_fraction ## W = 0.94732, p-value = 7.216e-09 El p-valor nos sale 0 en todas y por tanto no hay distribución normal de los datos, usaremos pues el test de Wilcoxon para compararlas con la variable de estudio. 4.2 Análisis bivariante Ahora analizaremos cada variable con la variable de estudio. Empezamos con las numéricas. A priori parece haber relación entre las variables numéricas y la variable de estudio. wilcox.test(datos$age ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$age by datos$DEATH_EVENT ## W = 7121, p-value = 0.0001668 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(datos$serum_creatinine ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$serum_creatinine by datos$DEATH_EVENT ## W = 5298, p-value = 1.581e-10 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(datos$serum_sodium ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$serum_sodium by datos$DEATH_EVENT ## W = 12262, p-value = 0.0002928 ## alternative hypothesis: true location shift is not equal to 0 wilcox.test(datos$ejection_fraction ~ datos$DEATH_EVENT, alternative=&quot;two.sided&quot;) ## ## Wilcoxon rank sum test with continuity correction ## ## data: datos$ejection_fraction by datos$DEATH_EVENT ## W = 13176, p-value = 7.368e-07 ## alternative hypothesis: true location shift is not equal to 0 Confirmamos que las variables están relacionadas con el evento DEATH ya que el p-valor nos ha salido 0 (rechazamos la hipótesis nula, que dice que las medias son iguales). Ahora veamos las variables categóricas. A simple vista parece que no hay relación alguna entre las variables categóricas y la variable de estudio, sin embargo vamos a comprobarlo haciendo el test chisq.test. chisq.test(xtabs(~ datos$anaemia + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$anaemia + datos$DEATH_EVENT) ## X-squared = 1.0422, df = 1, p-value = 0.3073 chisq.test(xtabs(~ datos$high_blood_pressure + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$high_blood_pressure + datos$DEATH_EVENT) ## X-squared = 1.5435, df = 1, p-value = 0.2141 chisq.test(xtabs(~ datos$creatinine_phosphokinase + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test ## ## data: xtabs(~datos$creatinine_phosphokinase + datos$DEATH_EVENT) ## X-squared = 2.3908, df = 2, p-value = 0.3026 chisq.test(xtabs(~ datos$platelets + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test ## ## data: xtabs(~datos$platelets + datos$DEATH_EVENT) ## X-squared = 3.0754, df = 2, p-value = 0.2149 chisq.test(xtabs(~ datos$diabetes + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$diabetes + datos$DEATH_EVENT) ## X-squared = 2.1617e-30, df = 1, p-value = 1 chisq.test(xtabs(~ datos$sex + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$sex + datos$DEATH_EVENT) ## X-squared = 0, df = 1, p-value = 1 chisq.test(xtabs(~ datos$smoking + datos$DEATH_EVENT)) ## ## Pearson&#39;s Chi-squared test with Yates&#39; continuity correction ## ## data: xtabs(~datos$smoking + datos$DEATH_EVENT) ## X-squared = 0.0073315, df = 1, p-value = 0.9318 Y como sospechábamos para todos el p-valor es mayor de 0.05 y por tanto las variables no están relacionadas. 4.3 Análisis multivariante Más adelante realizaremos la selección de variables de forma más adecuada pero mientras tanto mostramos el resultado del StepAIC utilizando todos los datos. # Modelo de regresión logística lr &lt;- stepAIC(glm(DEATH_EVENT~., data = datos, family = binomial(&quot;logit&quot;)), direction = &quot;both&quot;, trace = 0) summary(lr) ## ## Call: ## glm(formula = DEATH_EVENT ~ age + ejection_fraction + high_blood_pressure + ## serum_creatinine + serum_sodium, family = binomial(&quot;logit&quot;), ## data = datos) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.3376 -0.7712 -0.4978 0.8484 2.4941 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 3.95483 4.43338 0.892 0.372 ## age 0.05105 0.01249 4.086 4.38e-05 *** ## ejection_fraction -0.06705 0.01440 -4.657 3.21e-06 *** ## high_blood_pressure1 0.44276 0.29566 1.498 0.134 ## serum_creatinine 0.65503 0.16421 3.989 6.64e-05 *** ## serum_sodium -0.04774 0.03226 -1.480 0.139 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 375.35 on 298 degrees of freedom ## Residual deviance: 300.85 on 293 degrees of freedom ## AIC: 312.85 ## ## Number of Fisher Scoring iterations: 5 "],["kfold.html", "Capítulo 5 Validación y evaluación 5.1 K-fold cross validation 5.2 Métricas", " Capítulo 5 Validación y evaluación 5.1 K-fold cross validation Para la validación interna de los modelos vamos a implementar el procedimiento k-fold cross validation. A continuación mostraremos los pasos de nuestra implementación, donde se ha optado por no hacer un 5x2 sino un \\(k\\cdot (k-1)\\). Dividimos el dataset en k cajas. Asignamos 1 caja a test y k - 1 cajas a entrenamiento. Realizamos selección de variables con los datos de entrenamiento. Dividimos los datos de entrenamiento en 1 caja para validación y k - 2 para entrenamiento. Calculamos el AUC del primer conjunto de parámetros con los datos nuevos de entrenamiento y validación. Repetimos k - 2 veces más el último punto, moviendo las cajas hasta que cada caja del subconjunto se haya usado como validación. Se calcula la media del AUC y se realiza el mismo proceso con el siguiente conjunto de parámetros. Una vez probado todos los conjuntos de parámetros escogemos aquel con mayor AUC medio. Se calcula el AUC del modelo escogido usando ahora todos los datos de entrenamiento originales y los de test. Se repite todo lo anterior k - 1 veces más moviendo las cajas de entrenamiento original y la de test hasta que cada caja se haya usado como test. Al algoritmo se le pasarán como parámetros el dataset, el número de veces que queremos dividir el dataset, el algoritmo de aprendizaje, el método de selección de variables y los parámetros del algoritmo de aprendizaje. A continuación mostramos las funciones que implementan el algoritmo. Para este problema sería más adecuado el uso de un lenguaje orientado a objetos. get.variables &lt;- function(method, datos) { if (method == &quot;filtrado&quot;) { subset &lt;- chi.squared(DEATH_EVENT~., datos) subset &lt;- cutoff.k(subset, 5) return (as.simple.formula(subset, &quot;DEATH_EVENT&quot;)) } else if (method == &quot;wrapper&quot;) { lr &lt;- stepAIC(glm(DEATH_EVENT~., data = datos, family = binomial(&quot;logit&quot;)), direction = &quot;both&quot;, trace = 0) return (lr$formula) } } get.predictions &lt;- function(model, variables, parameters, training, test) { if (model == &quot;nn&quot;) { nn.fit &lt;- nnet(variables, data=training, size=parameters[[1]], maxit=1000, decay=parameters[[2]], trace=FALSE) return (predict(nn.fit, test, type=&quot;raw&quot;)) } else if (model == &quot;svm&quot;) { svm.fit &lt;- svm(variables, data=training, cost = parameters[[1]], gamma = parameters[[2]], probability=TRUE) pred &lt;- predict(svm.fit, test,probability=TRUE) return (attr(pred, which=&quot;probabilities&quot;)[,2]) } else if (model == &quot;tree&quot;) { dt.fit &lt;- rpart(variables, data=training, control = rpart.control(cp=parameters[[1]])) return(predict(dt.fit, test, type=&quot;vector&quot;)) } } k.fold.cross.validation &lt;- function(datos, k, model, method, parameters) { results &lt;- unname(data.frame()) parameters &lt;- expand.grid(pmt1 = parameters[[1]], pmt2 = parameters[[2]]) first.folded.data &lt;- createFolds(datos$DEATH_EVENT, k) for (i in 1:k) { best.inner.auc = 0 best.inner.model = parameters[1,] training.set &lt;- data.frame(datos[-unlist(first.folded.data[][i]),]) test.set &lt;- data.frame(datos[unlist(first.folded.data[][i]),]) second.folded.data &lt;- createFolds(training.set$DEATH_EVENT, k-1) #variables &lt;- get.variables(method, datos) variables &lt;- (DEATH_EVENT~serum_creatinine+ejection_fraction+age+serum_sodium) for (m in 1:nrow(parameters)) { # Calculamos la media de aucs de un mismo conjunto de parámetros model.auc &lt;- c() for (j in 1:(k-1)) { sub.training.set &lt;- data.frame(datos[-unlist(second.folded.data[][j]),]) validation.set &lt;- data.frame(datos[unlist(second.folded.data[][j]),]) pred &lt;- get.predictions(model, variables, parameters[m,], sub.training.set, validation.set) model.auc &lt;- c(model.auc, pROC::auc(validation.set$DEATH_EVENT, as.vector(pred), levels=c(0, 1))) } if (mean(model.auc) &gt; best.inner.auc) { best.inner.auc = mean(model.auc) best.inner.model = parameters[m,] } } pred &lt;- get.predictions(model, variables, best.inner.model, training.set, test.set) model.métricas = get.métricas(test.set$DEATH_EVENT, as.vector(pred)) results = rbind(results, unname(c(toString(variables), best.inner.model, model.métricas[1], model.métricas[4], model.métricas[5]))) } if (model == &quot;nn&quot;) names(results) &lt;- c(&quot;Variables&quot;, &quot;Size&quot;, &quot;Decay&quot;, &quot;ACC&quot;, &quot;F1-score&quot;, &quot;AUC&quot;) else if (model == &quot;svm&quot;) names(results) &lt;- c(&quot;Variables&quot;, &quot;Cost&quot;, &quot;Gamma&quot;, &quot;ACC&quot;, &quot;F1-score&quot;, &quot;AUC&quot;) else if (model == &quot;tree&quot;) { results &lt;- results[, -3] names(results) &lt;- c(&quot;Variables&quot;, &quot;Cp&quot;, &quot;ACC&quot;, &quot;F1-score&quot;, &quot;AUC&quot;) } return (results) } 5.2 Métricas Para la evaluación de los modelos nos guíamos por el AUC, aún así vamos a calcular también las métricas de precisión, especificidad, sensibilidad y F1-score, que están determinadas por el valor que fijemos como umbral y nos pueden servir de guía en caso de dudas cuando los resultados de AUC son similares. get.métricas &lt;- function(real, pred, print_matrix = FALSE) { roc.obj = pROC::roc(real, pred) auc = roc.obj$auc umbral = coords(roc.obj, &quot;best&quot;)[[1]] TP = length(which(pred &gt;= umbral &amp; real == 1)) TN = length(which(pred &lt;= umbral &amp; real == 0)) acc = (TP + TN) / length(pred) FP = length(which(pred &gt;= umbral &amp; real == 0)) FN = length(which(pred &lt;= umbral &amp; real == 1)) especificidad = TN / (TN + FP) sensibilidad = TP / (TP + FN) f1score = 2 * acc * sensibilidad / (acc + sensibilidad) v = cbind(c(TN, FN),c(FP, TP)) colnames(v) &lt;- c(&quot;F&quot;,&quot;T&quot;) rownames(v) &lt;- c(&quot;F&quot;,&quot;T&quot;) if (print_matrix) print(v) return(c(acc, especificidad, sensibilidad, f1score, auc)) } "],["res.html", "Capítulo 6 Resultados 6.1 Redes Neuronales 6.2 Máquinas de soporte vectorial 6.3 Árboles de decisión", " Capítulo 6 Resultados A continuación vamos a mostrar los resultados de los mejores modelos obtenidos de redes neuronales, máquinas de soporte vectorial y árboles de decisión. Para cada uno se ha empleado el método de filtrado chi.squared y el método wrapper stepAIC. Se muestran los valores de precisión, f1-score, y auc. Es importante destacar que las dos primeras medidas están completamente condicionadas por el umbral escogido para determinar qué probabilidades consideremos como 0 o 1. Nosotros hemos usado la función coords del paquete pROC para obtener ese cut-off. Lo dejamos así por si en un futuro conseguimos arreglar el problema no tener que modificar las tablas. Table 6.1: Métricas de los algoritmos para k=10 ACC F1score Min. AUC Mean AUC Max. AUC NN wrapper 0.7716500 0.7853928 0.6444444 0.7858651 0.8900000 NN filtrado 0.7733370 0.8274347 0.6750000 0.7900476 0.9388889 SVM wrapper 0.7760882 0.8691756 0.6809524 0.7938598 0.8944444 SVM filtrado 0.7928773 0.8274362 0.6761905 0.7969259 0.9400000 DT wrapper 0.7560363 0.6009772 0.5500000 0.6926190 0.8023810 DT filtrado 0.7263107 0.6002322 0.5000000 0.6684127 0.7833333 Podemos observar que el mayor AUC medio y el mayor ACC medio se han obtenido con SVM usando un método de filtrado para la selección de variables. Todos los modelos han obtenido resultados muy similares, y atendiendo al AUC máximo, se consiguen valores muy buenos. El conjunto de variables correspondiente para ese modelo es el siguiente: serum_creatinine, ejection_fraction, age, serum_sodium y platelets. Corresponde a lo visto en el análisis bivariante, donde nuestras cuatro variables numéricas estaban relacionadas con el evento Death. Vimos que platelets no estaba relacionada pero para el conjunto de datos parece que incluirla junto al resto de variables ayuda con la predicción. Para más detalles de los resultados obtenidos en la tabla 6.1 ver las siguientes subsecciones. Para ver un poco mejor la dispersión de los resultados ver las figuras 6.1 y 6.2. Puede observarse que la diferencia de modelos en el AUC es más significativa que en ACC y vemos claramente que el modelo más robusto que consigue con máquinas de soporte vectorial, más consistente y medias más altas. Figure 6.1: Precisión de los modelos Figure 6.2: AUC de los modelos Ahora vamos a comprobar si obtenemos mejores resultados usando sólo las variables serum_creatinine y ejection_fraction como mencionamos al principio del trabajo, cuyos resultados podemos ver en la tabla 6.2. También vamos a ver los resultados utilizando únicamente las variables relacionadas obtenidas en el capítulo 4 (ver tabla 6.3). Table 6.2: Métricas de los algoritmos (dos variables) para k=10 ACC F1-score Min. AUC Mean AUC Max. AUC NN wrapper 0.8157805 0.7498166 0.5700000 0.7682209 0.9404762 NN filtrado 0.7857100 0.7373077 0.6225000 0.7734511 0.8875000 SVM wrapper 0.7827697 0.7831239 0.6523810 0.7685476 0.9142857 SVM filtrado 0.7993363 0.7924813 0.5875000 0.7683730 0.9111111 DT wrapper 0.7655951 0.6049186 0.6190476 0.6998810 0.8023810 DT filtrado 0.7490323 0.5832521 0.5071429 0.6834524 0.8694444 Table 6.3: Métricas de los algoritmos (cuatro variables) para k=10 ACC F1-score Min. AUC Mean AUC Max. AUC NN wrapper 0.7563107 0.8054173 0.6900000 0.7864259 0.8777778 NN filtrado 0.7772006 0.7611653 0.6349206 0.7668016 0.8950000 SVM wrapper 0.7765554 0.8737590 0.6250000 0.7947857 0.8714286 SVM filtrado 0.7700371 0.8414964 0.5950000 0.7880159 0.9600000 DT wrapper 0.7363107 0.6167726 0.6000000 0.6830952 0.7833333 DT filtrado 0.7500371 0.6277486 0.5500000 0.6983333 0.8333333 Podemos juntar todos los datos obtenidos en las tres pruebas, calculando la media de cada columna, y obtenemos la siguiente tabla: Table 6.4: Media de todos los algoritmos según un conjunto de variables para k=10 ACC F1-score Min. AUC Mean AUC Max. AUC serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7660499 0.7517748 0.6210979 0.7546217 0.8748413 serum_creatinine + ejection_fraction + age + serum_sodium 0.7610753 0.7543932 0.6158201 0.7529096 0.8701455 serum_creatinine + ejection_fraction 0.7830373 0.7084834 0.5930952 0.7436543 0.8875331 Los mejores resultados en precisión se han obtenido usando sólo dos variables. Vemos que no hay mucha diferencia entre usar un conjunto de variables u otro, y preferiblemente vamos a tender siempre a simplificar el modelo. Siendo la diferencia en AUC tan poco significativa y siendo el conjunto de dos variables el que más ACC obtiene de media, nos decantamos por usarlo como conjunto para el modelo. 6.1 Redes Neuronales Table 6.5: Resultados NN usando wrapper Variables ACC F1-score AUC ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8065 0.7495 0.7333 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7241 0.7981 0.8333 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8710 0.8340 0.8714 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7931 0.7854 0.7722 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8667 0.8198 0.8889 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8667 0.8320 0.8900 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6667 0.8000 0.7100 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8000 0.8471 0.8150 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6667 0.7273 0.7000 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6552 0.6609 0.6444 Table 6.5: Resultados NN usando filtrado Variables ACC F1-score AUC ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8667 0.8830 0.8850 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8276 0.9057 0.8889 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7000 0.7832 0.7302 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7931 0.7854 0.7111 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6774 0.8077 0.6905 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7333 0.8082 0.7250 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7000 0.7000 0.6750 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7000 0.7875 0.7750 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8387 0.8683 0.8810 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8966 0.9455 0.9389 summary(nn.wrapper.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6444 0.7158 0.7936 0.7859 0.8619 0.8900 summary(nn.filtrado.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6750 0.7146 0.7526 0.7900 0.8840 0.9389 6.2 Máquinas de soporte vectorial Table 6.6: Resultados SVM usando wrapper Variables ACC F1-score AUC ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8000 1.0000 0.8300 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8276 1.0000 0.8944 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7931 0.7447 0.7944 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6129 0.8411 0.6810 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7000 1.0000 0.8042 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8710 0.8431 0.8429 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8000 0.7333 0.6850 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6897 0.8364 0.7167 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8333 0.8182 0.8750 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8333 0.8750 0.8150 Table 6.6: Resultados SVM usando filtrado Variables ACC F1-score AUC ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6897 0.8364 0.7222 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7333 0.7176 0.6850 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.9333 1.0000 0.9400 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8333 0.8095 0.8783 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8333 0.8750 0.8200 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7000 0.7600 0.7150 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8966 0.8588 0.8833 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7931 0.7857 0.8111 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7097 0.7632 0.6762 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8065 0.8681 0.8381 summary(svm.wrapper.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6810 0.7361 0.8096 0.7939 0.8396 0.8944 summary(svm.filtrado.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.6762 0.7168 0.8156 0.7969 0.8683 0.9400 6.3 Árboles de decisión Table 6.7: Resultados DT usando wrapper Variables ACC F1-score AUC ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8387 0.7631 0.8024 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7931 0.6534 0.7278 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7333 0.5946 0.6750 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7097 0.5867 0.6548 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7586 0.7097 0.7333 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7097 0.4217 0.6024 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.8333 0.6977 0.7750 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7241 0.5508 0.6472 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.6667 0.3077 0.5500 ~, DEATH_EVENT, age + ejection_fraction + high_blood_pressure + serum_creatinine + serum_sodium 0.7931 0.7244 0.7583 Table 6.7: Resultados DT usando filtrado Variables ACC F1-score AUC ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6333 0.3040 0.5250 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7667 0.7830 0.7750 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.6000 0.5455 0.5000 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.8276 0.7385 0.7833 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7667 0.6732 0.7250 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7419 0.5974 0.6786 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7241 0.7500 0.7389 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7097 0.4217 0.6024 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7931 0.5697 0.6972 ~, DEATH_EVENT, serum_creatinine + ejection_fraction + age + serum_sodium + platelets 0.7000 0.6195 0.6587 summary(dt.wrapper.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.5500 0.6491 0.7014 0.6926 0.7521 0.8024 summary(dt.filtrado.results$AUC) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.5000 0.6165 0.6879 0.6684 0.7354 0.7833 "],["conclusiones.html", "Capítulo 7 Conclusiones", " Capítulo 7 Conclusiones Hemos podido obtener modelos con un AUC mayor de 0.9 lo cual consideramos un éxito de cara a desplegar un futuro predictor. Sería conveniente contar con más datos ya que la muestra es relativamente pequeña y corremos el riesgo de sobreentrenar nuestros modelos. Si tuviésemos que quedarnos con un modelo sería con las máquinas de soporte vectorial usando algún método de filtrado, ya que como puede verse en el desglose de resultados del capítulo 6 llegábamos a conseguir un ACC de 0.93 y un AUC de 0.94. Los árboles de decisión son muy inconsistentes y son los que menor precisión consiguen, las redes neuronales son una buena opción pero requieren de mayor tiempo de entrenamiento. En los diagramas de bloques vimos que las máquinas de soporte vectorial son las que menor dispersión tienen en sus resultados y además de media obtienen mejores métricas, sumándole que son más rápidas que las redes neuronales (al menos en este proyecto) no hay dudas en que es nuestra mejor opción. Con respecto a la selección de variables no hemos visto gran diferencia entre las opciones propuestas, hemos sido capaces de obtener buenos resultados utilizando únicamente dos variables y por tanto merece la pena quedarse con un conjunto así de pequeño, ya que ayudará a mejorar el rendimiento de los modelos. "],["referencias.html", "Referencias", " Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
